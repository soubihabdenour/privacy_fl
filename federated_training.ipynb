{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Federated Training of CNNs on MNIST, CIFAR-10, and CIFAR-100 (No Flower)\n",
    "\n",
    "This notebook demonstrates a simple, standalone federated learning simulation **without** Flower. It trains ResNet-18, MobileNetV2, and AlexNet on MNIST, CIFAR-10, or CIFAR-100 using a basic FedAvg loop. Each round saves the model update for every client so you can inspect or reuse them later.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Tuple\n",
    "\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader, Dataset, Subset\n",
    "from torchvision import datasets, models, transforms\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {DEVICE}\")\n",
    "\n",
    "BASE_DIR = Path(\"model_updates\")\n",
    "BASE_DIR.mkdir(exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Dataset utilities\n",
    "\n",
    "The helpers below download datasets, apply standard normalization transforms, and partition training data across a configurable number of clients.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_transforms(dataset: str):\n",
    "    dataset = dataset.lower()\n",
    "    if dataset == \"mnist\":\n",
    "        # Replicate the grayscale channel so models expecting RGB inputs still work.\n",
    "        mean, std = (0.1307, 0.1307, 0.1307), (0.3081, 0.3081, 0.3081)\n",
    "        size = 28\n",
    "        tfms = [transforms.Resize(size), transforms.Grayscale(num_output_channels=3)]\n",
    "    else:\n",
    "        mean, std = (0.4914, 0.4822, 0.4465), (0.2470, 0.2435, 0.2616)\n",
    "        size = 32\n",
    "        tfms = [transforms.Resize(size)]\n",
    "    tfms.extend([transforms.ToTensor(), transforms.Normalize(mean, std)])\n",
    "    return transforms.Compose(tfms)\n",
    "\n",
    "\n",
    "def load_datasets(dataset: str, data_dir: str = \"./data\") -> Tuple[Dataset, Dataset]:\n",
    "    dataset = dataset.lower()\n",
    "    tfm = get_transforms(dataset)\n",
    "    if dataset == \"mnist\":\n",
    "        train = datasets.MNIST(data_dir, train=True, download=True, transform=tfm)\n",
    "        test = datasets.MNIST(data_dir, train=False, download=True, transform=tfm)\n",
    "    elif dataset == \"cifar10\":\n",
    "        train = datasets.CIFAR10(data_dir, train=True, download=True, transform=tfm)\n",
    "        test = datasets.CIFAR10(data_dir, train=False, download=True, transform=tfm)\n",
    "    elif dataset == \"cifar100\":\n",
    "        train = datasets.CIFAR100(data_dir, train=True, download=True, transform=tfm)\n",
    "        test = datasets.CIFAR100(data_dir, train=False, download=True, transform=tfm)\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported dataset: {dataset}\")\n",
    "    return train, test\n",
    "\n",
    "\n",
    "def partition_dataset(dataset: Dataset, num_clients: int) -> List[Subset]:\n",
    "    indices = torch.randperm(len(dataset))\n",
    "    shards = torch.chunk(indices, num_clients)\n",
    "    return [Subset(dataset, shard.tolist()) for shard in shards]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model builders\n\nWe reuse torchvision reference implementations. AlexNet and other ImageNet-style backbones expect 3-channel inputs, so MNIST images are converted to RGB via the transform above.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(arch: str, num_classes: int) -> nn.Module:\n",
    "    arch = arch.lower()\n",
    "    if arch == \"resnet18\":\n",
    "        model = models.resnet18(weights=None)\n",
    "        model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
    "    elif arch == \"mobilenetv2\":\n",
    "        model = models.mobilenet_v2(weights=None)\n",
    "        model.classifier[1] = nn.Linear(model.classifier[1].in_features, num_classes)\n",
    "    elif arch == \"alexnet\":\n",
    "        model = models.alexnet(weights=None)\n",
    "        model.classifier[6] = nn.Linear(model.classifier[6].in_features, num_classes)\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported architecture: {arch}\")\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Training and evaluation helpers\n",
    "\n",
    "Each client performs standard supervised training locally. The server aggregates client weights via FedAvg, and we log accuracy after every round.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_client(model: nn.Module, loader: DataLoader, epochs: int, lr: float) -> Tuple[nn.Module, float]:\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.SGD(model.parameters(), lr=lr, momentum=0.9, weight_decay=5e-4)\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    for _ in range(epochs):\n",
    "        for images, labels in loader:\n",
    "            images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item() * images.size(0)\n",
    "    avg_loss = total_loss / len(loader.dataset)\n",
    "    return model, avg_loss\n",
    "\n",
    "\n",
    "def evaluate(model: nn.Module, loader: DataLoader) -> float:\n",
    "    model.eval()\n",
    "    correct, total = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in loader:\n",
    "            images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
    "            outputs = model(images)\n",
    "            preds = outputs.argmax(dim=1)\n",
    "            correct += (preds == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "    return correct / total\n",
    "\n",
    "\n",
    "def fedavg(global_model: nn.Module, client_states: List[Dict[str, torch.Tensor]]):\n",
    "    avg_state: Dict[str, torch.Tensor] = {}\n",
    "    for key in global_model.state_dict().keys():\n",
    "        tensors = [state[key] for state in client_states]\n",
    "        if tensors[0].dtype.is_floating_point:\n",
    "            stacked = torch.stack([t.detach() for t in tensors], dim=0)\n",
    "            avg_state[key] = stacked.mean(dim=0)\n",
    "        else:\n",
    "            avg_state[key] = tensors[0].detach().clone()\n",
    "    global_model.load_state_dict(avg_state)\n",
    "    return global_model\n",
    "\n",
    "\n",
    "def save_client_update(round_idx: int, client_idx: int, global_before: Dict[str, torch.Tensor], client_after: Dict[str, torch.Tensor]):\n",
    "    update = {k: client_after[k].cpu() - global_before[k].cpu() for k in global_before.keys()}\n",
    "    path = BASE_DIR / f\"round_{round_idx:03d}_client_{client_idx:02d}.pt\"\n",
    "    torch.save(update, path)\n",
    "    return path\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Federated simulation loop\n",
    "\n",
    "The `run_federated_training` function orchestrates the process:\n",
    "1. Load and partition the dataset across clients.\n",
    "2. Train each client locally for a few epochs.\n",
    "3. Save every client's model update for the round.\n",
    "4. Aggregate updates into the global model via FedAvg.\n",
    "5. Evaluate the global model after each round.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_federated_training(\n",
    "    dataset: str = \"mnist\",\n",
    "    architecture: str = \"resnet18\",\n",
    "    num_clients: int = 5,\n",
    "    client_epochs: int = 1,\n",
    "    rounds: int = 3,\n",
    "    batch_size: int = 64,\n",
    "    lr: float = 0.01,\n",
    "):\n",
    "    train_ds, test_ds = load_datasets(dataset)\n",
    "    num_classes = len(train_ds.classes) if hasattr(train_ds, \"classes\") else 10\n",
    "    clients = partition_dataset(train_ds, num_clients)\n",
    "\n",
    "    test_loader = DataLoader(test_ds, batch_size=batch_size, shuffle=False, num_workers=2, pin_memory=torch.cuda.is_available())\n",
    "\n",
    "    global_model = build_model(architecture, num_classes).to(DEVICE)\n",
    "\n",
    "    history = {\"round\": [], \"accuracy\": []}\n",
    "    for rnd in range(1, rounds + 1):\n",
    "        client_states = []\n",
    "        global_before = {k: v.detach().clone() for k, v in global_model.state_dict().items()}\n",
    "\n",
    "        for cid, subset in enumerate(clients):\n",
    "            loader = DataLoader(subset, batch_size=batch_size, shuffle=True, num_workers=2, pin_memory=torch.cuda.is_available())\n",
    "            client_model = build_model(architecture, num_classes).to(DEVICE)\n",
    "            client_model.load_state_dict(global_model.state_dict())\n",
    "            client_model, loss = train_one_client(client_model, loader, epochs=client_epochs, lr=lr)\n",
    "            client_state = {k: v.detach().clone() for k, v in client_model.state_dict().items()}\n",
    "            client_states.append(client_state)\n",
    "            path = save_client_update(rnd, cid, global_before, client_state)\n",
    "            print(f\"Saved update for round {rnd}, client {cid} at {path}\")\n",
    "\n",
    "        global_model = fedavg(global_model, client_states)\n",
    "        acc = evaluate(global_model, test_loader)\n",
    "        history[\"round\"].append(rnd)\n",
    "        history[\"accuracy\"].append(acc)\n",
    "        print(f\"Round {rnd}: global accuracy={acc:.4f}\")\n",
    "\n",
    "    return global_model, history\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Example run (quick sanity check)\n",
    "\n",
    "The example below runs a very small simulation for speed. Increase the number of rounds, clients, or epochs for more meaningful results.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Warning: running this cell will download datasets if not already present.\n",
    "# To keep runtime short in limited environments, use small values.\n",
    "\n",
    "model, history = run_federated_training(\n",
    "    dataset=\"mnist\", architecture=\"resnet18\", num_clients=3, client_epochs=1, rounds=2, batch_size=64, lr=0.01\n",
    ")\n",
    "print(history)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}